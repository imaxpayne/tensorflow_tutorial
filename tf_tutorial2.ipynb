{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax regressions\n",
    "\n",
    "This is the second introduction on tensorflow for RVL224 students.\n",
    "\n",
    "In this section, you will learn:\n",
    "\n",
    "* What is softmax regressions.\n",
    "* The basic concept behind softmax regressions.\n",
    "* How to impliment it using tensorflow to classify **mnist** dataset.\n",
    "\n",
    "\n",
    "**Softmax regressions** is a classifier that can assign probabilities to each class given an input, for example, if you feed the following picture \n",
    "<img src=\"http://bradleymitchell.me/wp-content/uploads/2014/06/decompressed.jpg\" width=\"128\" height=\"128\" />\n",
    "\n",
    "into a trained softmax classifier, it might assign the probability of been 5 is 0.96, and probability of been 9 is 0.03, and a bit of probability to others, which sum up to 1.0.\n",
    "\n",
    "A softmax regression has two steps: first we add up the evidence of our input being in certain classes, and then we convert that evidence into probabilities.\n",
    "\n",
    "The evidence for a class $i$ given an input $x$ is:\n",
    "$$\n",
    "\\text{evidence}_i = \\sum_j W_{i,~ j} x_j + b_i\n",
    "$$\n",
    "where $W_i$ is the weights and $b_i$ is the bias for class $i$, and $j$ is the index  for summing over the pixels in our input image $x$, We then convert the evidence tallies into our predicted probabilities $y$ using the \"softmax\" function:\n",
    "\n",
    "$$\n",
    "y = \\text{softmax}(\\text{evidence})\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "You can picture our softmax regression as looking something like the following:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/softmax-regression-scalargraph.png\" width=\"323\" height=\"129\" />\n",
    "\n",
    "where $x$ is pixels of one input picture, and $y$ is the prbabilities for each class. We can write that out as a equation like:\n",
    "\n",
    "<img src=\"https://www.tensorflow.org/images/softmax-regression-vectorequation.png\" width=\"328\" height=\"80\" />\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Now, let's impliment it using tensorflow to classify hand-written digits from MNIST dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and extract dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist  = input_data.read_data_sets('/tmp/data/', one_hot=True) #load dataset\n",
    "train_img   = mnist.train.images\n",
    "train_label = mnist.train.labels\n",
    "test_img    = mnist.test.images\n",
    "test_label  = mnist.test.labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the computational graph for softmax regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "# create an input node with shape [None, 784] so we can feed images later, \n",
    "# note that 'None' means an arbitrary size.\n",
    "x = tf.placeholder(\"float\", [None, 784]) \n",
    "print (tf.__version__)\n",
    "\n",
    "# create an input node so we can feed labels later.\n",
    "y_ = tf.placeholder(\"float\", [None, 10]) \n",
    "\n",
    "\n",
    "\n",
    "W = tf.Variable(tf.zeros([784, 10])) # create Weights variable and initrailize to all zero\n",
    "b = tf.Variable(tf.zeros([10]))# create bias variable \n",
    "\n",
    "\n",
    "evidence = tf.matmul(x, W) + b\n",
    "prob = tf.nn.softmax(evidence)\n",
    "\n",
    "\n",
    "# COST FUNCTION\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = evidence,labels = y_)) \n",
    "# OPTIMIZER\n",
    "learning_rate = 0.005\n",
    "optm = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-d486eea1fc51>:6: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "# PREDICTION\n",
    "pred = tf.equal(tf.argmax(prob, 1), tf.argmax(y_, 1))    \n",
    "# ACCURACY\n",
    "accr = tf.reduce_mean(tf.cast(pred, \"float\"))\n",
    "# INITIALIZER\n",
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000/050 cost: 1.477954281 train_acc: 0.810 test_acc: 0.832\n",
      "Epoch: 005/050 cost: 0.533739885 train_acc: 0.890 test_acc: 0.882\n",
      "Epoch: 010/050 cost: 0.446352980 train_acc: 0.870 test_acc: 0.893\n",
      "Epoch: 015/050 cost: 0.408236921 train_acc: 0.900 test_acc: 0.899\n",
      "Epoch: 020/050 cost: 0.385582237 train_acc: 0.870 test_acc: 0.904\n",
      "Epoch: 025/050 cost: 0.370123066 train_acc: 0.950 test_acc: 0.907\n",
      "Epoch: 030/050 cost: 0.358701173 train_acc: 0.870 test_acc: 0.909\n",
      "Epoch: 035/050 cost: 0.349740249 train_acc: 0.850 test_acc: 0.910\n",
      "Epoch: 040/050 cost: 0.342516444 train_acc: 0.900 test_acc: 0.912\n",
      "Epoch: 045/050 cost: 0.336515801 train_acc: 0.920 test_acc: 0.913\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "training_epochs = 50\n",
    "batch_size      = 100\n",
    "display_step    = 5\n",
    "# SESSION\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "# MINI-BATCH LEARNING\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0.\n",
    "    num_batch = int(mnist.train.num_examples/batch_size)\n",
    "    for i in range(num_batch): \n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        sess.run(optm, feed_dict={x: batch_xs, y_: batch_ys})\n",
    "        feeds = {x: batch_xs, y_: batch_ys}\n",
    "        avg_cost += sess.run(cost, feed_dict=feeds)/num_batch\n",
    "    \n",
    "    \n",
    "    # DISPLAY\n",
    "    if epoch % display_step == 0:\n",
    "        feeds_train = {x: batch_xs, y_: batch_ys}\n",
    "        feeds_test = {x: mnist.test.images, y_: mnist.test.labels}\n",
    "        train_acc = sess.run(accr, feed_dict=feeds_train)\n",
    "        test_acc = sess.run(accr, feed_dict=feeds_test)\n",
    "        print (\"Epoch: %03d/%03d cost: %.9f train_acc: %.3f test_acc: %.3f\" \n",
    "               % (epoch, training_epochs, avg_cost, train_acc, test_acc))\n",
    "print (\"DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find that it achives about 92% of accurracy after 50 epoch, next we will impliment a Neural Net which can achive even better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## exercise \n",
    "\n",
    "plase adjust the hyperperameters such as batch size, training epoch and learning rate, observe  the effects.\n",
    "\n",
    "Also randomly choose images in test dataset and feed into the trained softmax, see if it can acctually predict the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
